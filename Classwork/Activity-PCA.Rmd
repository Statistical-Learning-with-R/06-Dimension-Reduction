---
title: "Model Selection in Regression"
author: "YOUR NAME"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)

library(tidyverse)
library(tidymodels)
library(leaps)


set.seed(98249)
```

## Data Prep

```{r}
cann <- read_csv("https://www.dropbox.com/s/s2a1uoiegitupjc/cannabis_full.csv?dl=1")

cann_matrix <- cann %>%
  select(-Type, -Strain, -Effects, -Flavor, -Dry, -Mouth) %>%
  as.matrix()
```

## Code from Lecture

```{r, echo = FALSE}
# Read data
fed <- read.csv("https://www.dropbox.com/s/9t8sxr1sg0monih/federalist.txt?dl=1")
fed <- fed[,-1]

# Keep numeric section only
fed_all <- as.matrix(fed[,-1])
fed_all <- apply(fed_all, 2, as.numeric)

auths <- fed$Author

# Data from papers with known authors
fed_known <- as.matrix(fed[auths != 'DIS',-1])
fed_known <- apply(fed_known, 2, as.numeric)

auths_known = auths[auths != 'DIS']


fed_ex <- as_tibble(fed_known) %>% cbind(auths_known)
```

If we choose a couple words and plot our data...

```{r, echo = FALSE}
fed_ex %>%
  ggplot(aes(x = there, y = would, color = auths_known)) +
  geom_point()
```


Instead, let's apply pca:

```{r}
fed_matrix <- fed_ex %>% select(-auths_known) %>% as.matrix()
pc <- prcomp(fed_matrix, center = TRUE, scale = TRUE)
```


Combinations of variables that create new axes:

```{r}
pc$rotation
```


```{r}
pcs_df <- pc$rotation %>%
  as.data.frame() %>%
  rownames_to_column() 

pcs_df %>%
  arrange(desc(abs(PC1)))
```

This doesn't really help us visualize the data...

```{r, echo = FALSE}
fed_ex %>%
  ggplot(aes(x = and, y = of, color = auths_known)) +
  geom_point()
```


```{r}
new_dims_df <- pc$x %>%
  as.data.frame()

new_dims_df
```

```{r}
new_dims_df %>%
  ggplot(aes(x = PC1, y = PC2, color = auths_known)) +
  geom_point()
```


```{r}
pc$sdev
```

```{r}
cumul_vars <- cumsum(pc$sdev^2)/sum(pc$sdev^2)
cumul_vars
```


```{r}
plot(cumul_vars)
```


## Try it!

#### Apply PCA to the cannabis data
#### Interpret the PC rotations
#### Plot the data on the first two axes, and color by Type.
#### Choose a "good" number of PCs to use.
#### Fit a KNN classifier using only your chosen PCs.  How does the accuracy compare to when you use all the original predictors?

